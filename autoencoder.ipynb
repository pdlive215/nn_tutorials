{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTOENCODERS** (work in progress)\n",
    "\n",
    "*Patrick Donnelly*\n",
    "\n",
    "In this tutorial, we'll take a look at **autoencoder** networks. Autoencoders are kinda weird if you haven't seen them before. They take an input and learn a function to, uh, reproduce the input. This function is a neural network that passes the input through a \"bottleneck\" before \"reconstructing\" the input in the output layer (see https://www.jeremyjordan.me/autoencoders/). Why on earth would we want to do this? Well, the bottleneck gives us a compressed representation of our input, and we can then train the network to minimize the loss associated with the reconstruction of the input. \n",
    "\n",
    "As with our other tutorials, we'll use simple data in order to focus on the operations associated with constructing different autoencoder architectures. We'll experiment with some \"vanilla\" autoencoders and then move on to regularized, variational, and other autoencoders. As always, we will implement these networks in PyTorch.\n",
    "\n",
    "Let's begin by defining a simple autoencoder architecture. We'll use the `vae` example from the PyTorch `examples` directory as reference. First we'll need to import some packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our `VAE` class and constructor. This will inherit from the `nn` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we define our network architecture, let's build some toy data. We're going to start with a familiar example: a 5x5 \"zero digit\" of one-bit pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_zero = [[0,1,1,1,0],[1,0,0,0,1],[1,0,0,0,1],[1,0,0,0,1],[0,1,1,1,0]]\n",
    "a_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the zero? Cool. Now we want to define that as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_zero_vector = [0,1,1,1,0,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,0,1,1,1,0]\n",
    "a_zero_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were doing image classification, we'd now want to define a label (e.g. a one-hot encoding vector) as our output. But since we're constructing an autoencoder, we actually already have our output. It's our input! Now we know the number of input and output nodes - it's just the length of `a_zero_vector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_zero_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need our bottleneck. Let's start by adding a set of hidden nodes. We want our bottleneck to contain fewer nodes than our input and output layers. How about 10 nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(25, 10)\n",
    "        self.fc2 = nn.Linear(10, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear` defines a linear transformation (with bias) mapping input to output nodes. The number of nodes is passed as an argument. In this case, we have 25 input nodes and 10 output nodes for our first layer, and 10 input nodes and 25 output nodes for our second layer. By convention, we'll call our **fully-connected** layers `fc1` and `fc2`.\n",
    "\n",
    "To begin experimenting with PyTorch, we'll need to convert our example \"image\" to a `tensor`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(a_zero_vector, requires_grad=False).float()\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define an `encode` method. This will pass the output of our first linear transformation through a `ReLu` activation function. We can define `ReLu` using the `nn` module, but let's follow our PyTorch examples code and use the `functional` API. First we import the `nn.functional` module (by convention) as `F`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a simple `encode` method. This will take our \"image\" `x` as input, pass it through the fully-connected layer `fc1` and apply a `relu` activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also build a `decode` method. This will apply a `sigmoid` activation to the output of the `fc2` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(self, x):\n",
    "    x = F.sigmoid(self.fc2(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks kinda verbose for a simple vanilla autoencoder, but it'll make sense as we expand the networ. We're sticking to the template in the PyTorch `examples` directory.\n",
    "\n",
    "Now we just need a `forward` method that defines how the data propagates through our encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.encode(x)\n",
    "    return self.decode(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(25, 10)\n",
    "        self.fc2 = nn.Linear(10, 25)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "        \n",
    "    def decode(self, x):\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call an instance of our autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (fc1): Linear(in_features=25, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = VAE()\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now feed our input through the instance of our autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pp/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4703, 0.4871, 0.4439, 0.4296, 0.4083, 0.4344, 0.4225, 0.5771, 0.5311,\n",
       "        0.4970, 0.5918, 0.4605, 0.5516, 0.4299, 0.5474, 0.4411, 0.3807, 0.5126,\n",
       "        0.5438, 0.5133, 0.5032, 0.5225, 0.4660, 0.5765, 0.5075],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We can see that our autoencoder didn't do a great job of reconstructing our input. After all, it hasn't actually learned anything yet. We just passed the data through the network. We haven't backpropagated.\n",
    "\n",
    "How do we measure our **reconstruction loss**?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
