{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEEP LEARNING IN FIVE DAYS**\n",
    "\n",
    "*Patrick Donnelly*\n",
    "\n",
    "Day one: Defining a use case for deep learning\n",
    "\n",
    "Chapter two: Other computer vision applications and object detection\n",
    "\n",
    "So far we've looked at image classification, which accounts for maybe 90% of benchmark tests for deep learning (I'm exaggerating) and maybe 0.9% of practical applications. Even within computer vision, it's hard to do interesting things with a classification network alone.\n",
    "\n",
    "To stand on the shoulders of the internet, let's start with this nice blog post that enumerates common applications of DL for CV: https://machinelearningmastery.com/applications-of-deep-learning-for-computer-vision/\n",
    "\n",
    "Brownlee (the author) identifies nine applications, plus \"other problems\" in DL for CV:\n",
    "\n",
    "1. Image classification (we've already done this)\n",
    "2. Image classification with localization\n",
    "3. Object detection\n",
    "4. Object segmentation\n",
    "5. Image style transfer\n",
    "6. Image colorization\n",
    "7. Image reconstruction\n",
    "8. Image super-resolution\n",
    "9. Image synthesis\n",
    "\n",
    "We can also think of ways in which these problems can be extended to video. Think of video as multiple frames of images, or as an additional dimension.\n",
    "\n",
    "We'll group *image classification with localization* and *object detection* together. The former is just object detection with a single image. Most classification applications involve some form of detection first, since we often have to extract an object of interest from a photo (or video) before classifying it.\n",
    "\n",
    "We're gonna spend the rest of this chapter diving into object detection using the Faster R-CNN network (https://arxiv.org/abs/1506.01497). We'll explain more about what exactly this network does, but let's dive in to the code first!\n",
    "\n",
    "PyTorch has a package called `torchvision` that implements Faster R-CNN and other neural networks for computer vision. Let's import it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `faster_rcnn.py` code resides in https://github.com/pytorch/vision/blob/master/torchvision/models/detection/faster_rcnn.py. Let's take care of our imports. We'll modify the relative imports since we're directly executing the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.models.detection as detection\n",
    "\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "\n",
    "from torchvision.models.detection.generalized_rcnn import GeneralizedRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
    "from torchvision.models.detection.roi_heads import RoIHeads\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
